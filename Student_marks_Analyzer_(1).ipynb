{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8lPskZRyyVKr"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzvruU3rBZ5G"
      },
      "source": [
        "Reading the file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pnn8WSAW6w-W"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv('/content/StudentsPerformance.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_ENtOoEBkft"
      },
      "outputs": [],
      "source": [
        "def print_data():\n",
        "  print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIGuuAQZxho9"
      },
      "source": [
        "Lets calculate the highest Score in Maths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sT-airuuxlcS"
      },
      "outputs": [],
      "source": [
        "def math_high():\n",
        " print(df.loc[df['math score']==df['math score'].max(),['gender', 'test preparation course','math score']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejwr7USt0dvk"
      },
      "source": [
        "Calculating highest score in reading score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0HzjpQgC0dIs"
      },
      "outputs": [],
      "source": [
        "def read_high():\n",
        " print(df.loc[df['reading score']==df['reading score'].max(),['gender','test preparation course','reading score']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1P20fzCN1GNr"
      },
      "source": [
        "Calculate the highest score in Writing score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCXBj6k0Lctt"
      },
      "outputs": [],
      "source": [
        "def writing_high():\n",
        " print(df.loc[df['writing score']==df['writing score'].max(),['gender','test preparation course','writing score']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSWLcZWm1PMp"
      },
      "source": [
        "Minimum score in math score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M4Wfecg_Lfjy"
      },
      "outputs": [],
      "source": [
        "def math_min():\n",
        " print(df.loc[df['math score']==df['math score'].min(),['gender','test preparation course','math score']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HXmIi_d1WxD"
      },
      "source": [
        "Minimum score in reading score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQvZOLx6LnsB"
      },
      "outputs": [],
      "source": [
        "def min_reading():\n",
        " print(df.loc[df['reading score']==df['reading score'].min(),['gender','test preparation course','reading score']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lev1eTDKLh2P"
      },
      "outputs": [],
      "source": [
        "def min_writing():\n",
        " print(df.loc[df['writing score']==df['writing score'].min(),['gender','test preparation course','writing score']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64uOMq1210x_"
      },
      "source": [
        "Average Score in math score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HjRkpwfg1zIL"
      },
      "outputs": [],
      "source": [
        "def avg_math():\n",
        " print(\"The average Math score is\",df['math score'].mean(skipna=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgV3xMew2yil"
      },
      "source": [
        "Average score in reading score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hrOJfFcU2rIZ"
      },
      "outputs": [],
      "source": [
        "def avd_read():\n",
        " print(\"The average reading score is\",df['reading score'].mean(skipna=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "290Dy-Ap22kE"
      },
      "source": [
        "Average in Writing score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4d6KIbZ2rsa"
      },
      "outputs": [],
      "source": [
        "def avg_writing():\n",
        " print(\"The average writng score is\",df['writing score'].mean(skipna=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcUZDEh527em"
      },
      "source": [
        "Lets calculate total score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3EDD7Ksi26Z1"
      },
      "outputs": [],
      "source": [
        "def total_marks():\n",
        " df['Total score']=df['math score']+df['writing score']+df['reading score']\n",
        " print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qze1psa63ecs"
      },
      "source": [
        "Highest scorers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s9CzlBih3iLq"
      },
      "outputs": [],
      "source": [
        "def highest_score():\n",
        " print(df.loc[df['Total score']==df['Total score'].max(),['gender','test preparation course','Total score']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKW6sBma4HOT"
      },
      "source": [
        "Lowest scorers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EMXFWSPe4GtW"
      },
      "outputs": [],
      "source": [
        "def lowest_score():\n",
        " print(df.loc[df['Total score']==df['Total score'].min(),['gender','test preparation course','Total score']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41SVsiOm4Mpc"
      },
      "source": [
        "Average scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TKgBcoe4PDF"
      },
      "outputs": [],
      "source": [
        "def avg_score():\n",
        " print('The Average Score',df['Total score'].mean(skipna=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGS4DNCyioSP"
      },
      "source": [
        "Reccomendation courses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjftSi_1FMCe"
      },
      "outputs": [],
      "source": [
        "def recommend(row):\n",
        "    if row['math score'] < 60 and row['reading score'] > 75:\n",
        "        return 'Needs Math Support'\n",
        "    elif row['math score'] > 85 and row['reading score'] > 85 and row['writing score'] > 85:\n",
        "        return 'High Achiever – Recommend Advanced Courses'\n",
        "    elif row['math score'] < 60 and row['reading score'] < 60 and row['writing score'] < 60:\n",
        "        return 'General Academic Support'\n",
        "    else:\n",
        "        return 'No Specific Recommendation'\n",
        "\n",
        "    df['Recommendation'] = df.apply(recommend, axis=1)\n",
        "    print(df)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRNL6chSitg6"
      },
      "source": [
        "To check what course is recommended by entering the total marks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YKVnk8qtjEeK"
      },
      "outputs": [],
      "source": [
        "def recommend_course(total_score):\n",
        "    if total_score >= 270:\n",
        "        return \"High Achiever — Recommend Advanced Courses\"\n",
        "    elif total_score <= 150:\n",
        "        return \"General Academic Support\"\n",
        "    else:\n",
        "        return \"No Specific Recommendation\"\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXFUQVz-ibLs"
      },
      "source": [
        "Graph of Average math score by gender"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f08IW9LyFfZy"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4B3qAJduDSp4"
      },
      "outputs": [],
      "source": [
        "def bar_plot():\n",
        "\n",
        "# Example: Average math score by gender\n",
        " avg_scores = df.groupby('gender')['math score'].mean()\n",
        "\n",
        " avg_scores.plot(kind='bar', color='Green')\n",
        " plt.title('Average Math Score by Gender')\n",
        " plt.ylabel('Average Score')\n",
        " plt.xlabel('Gender')\n",
        " plt.grid(True)\n",
        " plt.show(block=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJ_t7tyEigcq"
      },
      "source": [
        "Reading v/s Writing Scatter plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFAItTaUDYQZ"
      },
      "outputs": [],
      "source": [
        "def scatter_plot():\n",
        " plt.scatter(df['reading score'], df['writing score'], color='purple')\n",
        " plt.title('Reading vs Writing Score')\n",
        " plt.xlabel('Reading Score')\n",
        " plt.ylabel('Writing Score')\n",
        " plt.grid(True)\n",
        " plt.show(block=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYxJz-e3H2oi"
      },
      "source": [
        "Test Preparation Course effect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27FpNOPHIJf4"
      },
      "outputs": [],
      "source": [
        "def test_effect():\n",
        "\n",
        " prep_avg = df.groupby('test preparation course')[['math score', 'reading score', 'writing score']].mean()\n",
        "\n",
        " prep_avg.plot(kind='bar', figsize=(8, 6))\n",
        " plt.title('Average Scores by Test Preparation Course')\n",
        " plt.ylabel('Average Score')\n",
        " plt.xticks(rotation=0)\n",
        " plt.grid(axis='y')\n",
        " plt.show(block=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UCS_dgZIrZ3",
        "outputId": "acebdbc4-fb27-422a-fb4d-140c75489763"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "*** 1.Print the Data                             ****\n",
            "*** 2.Highes Scores in Math                      ****\n",
            "*** 3.Lowest Scores in Math                      ****\n",
            "*** 4.Highest Scores in Reading                  ****\n",
            "*** 5.Lowest Scores in Reading                   ****\n",
            "*** 6.Highest Scores in Writing                  ****\n",
            "*** 7.Lowest Score in Writing                    ****\n",
            "*** 8.Average Score in Math                      ****\n",
            "*** 9.Average Score in Reading                  ****\n",
            "*** 10.Average Score in Writng                   ****\n",
            "*** 11.Total Scores                              ****\n",
            "*** 12.Highest Total Score                       ****\n",
            "*** 13.Average Total Score                       ****\n",
            "*** 14.Lowest Total Score                        ****\n",
            "*** 15.Check Reccomendation courses               ***\n",
            "*** 16.Check course Reccomendation by Total marks ***\n",
            "*** 17.Graph of Average math score by gender      ***\n",
            "*** 18.Reading v/s Writing Scatter plot           ***\n",
            "*** 19.Test Preparation Course effect             ***\n",
            "*** Enter 0 to Quit                               ***\n"
          ]
        }
      ],
      "source": [
        "  print(\"*** 1.Print the Data                             ****\")\n",
        "  print(\"*** 2.Highes Scores in Math                      ****\")\n",
        "  print(\"*** 3.Lowest Scores in Math                      ****\")\n",
        "  print(\"*** 4.Highest Scores in Reading                  ****\")\n",
        "  print(\"*** 5.Lowest Scores in Reading                   ****\")\n",
        "  print(\"*** 6.Highest Scores in Writing                  ****\")\n",
        "  print(\"*** 7.Lowest Score in Writing                    ****\")\n",
        "  print(\"*** 8.Average Score in Math                      ****\")\n",
        "  print(\"*** 9.Average Score in Reading                  ****\")\n",
        "  print(\"*** 10.Average Score in Writng                   ****\")\n",
        "  print(\"*** 11.Total Scores                              ****\")\n",
        "  print(\"*** 12.Highest Total Score                       ****\")\n",
        "  print(\"*** 13.Average Total Score                       ****\")\n",
        "  print(\"*** 14.Lowest Total Score                        ****\")\n",
        "\n",
        "  print(\"*** 15.Check Reccomendation courses               ***\")\n",
        "  print(\"*** 16.Check course Reccomendation by Total marks ***\")\n",
        "  print(\"*** 17.Graph of Average math score by gender      ***\")\n",
        "  print(\"*** 18.Reading v/s Writing Scatter plot           ***\")\n",
        "  print(\"*** 19.Test Preparation Course effect             ***\")\n",
        "  print(\"*** Enter 0 to Quit                               ***\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1dDJS6sGP9h"
      },
      "source": [
        "**Options**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "NEC50S6jZW3b",
        "outputId": "a7fe22f8-415a-4f38-b595-2221fe298e4d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b581266ed9be>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mchoice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter the choice: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchoice\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Exiting...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "while True:\n",
        "    choice = int(input(\"Enter the choice: \"))\n",
        "\n",
        "    if choice == 0:\n",
        "        print(\"Exiting...\")\n",
        "        break\n",
        "    elif choice == 1:\n",
        "        print_data()\n",
        "    elif choice == 2:\n",
        "        math_high()\n",
        "    elif choice==3:\n",
        "      math_min()\n",
        "    elif choice==4:\n",
        "       read_high()\n",
        "    elif choice==5:\n",
        "       min_reading()\n",
        "    elif choice==6:\n",
        "       writing_high()\n",
        "    elif choice==7:\n",
        "      min_writing()\n",
        "    elif choice==8:\n",
        "       avg_math()\n",
        "    elif choice==9:\n",
        "        avd_read()\n",
        "    elif choice==10:\n",
        "      avg_writing()\n",
        "    elif choice==11:\n",
        "       total_marks()\n",
        "    elif choice==12:\n",
        "      highest_score()\n",
        "    elif choice==13:\n",
        "       avg_score()\n",
        "    elif choice==14:\n",
        "      lowest_score()\n",
        "    elif choice==15:\n",
        "      df['Recommendation'] = df.apply(recommend, axis=1)\n",
        "      print(df)\n",
        "    elif choice==16:\n",
        "      math = int(input(\"Enter Math Score: \"))\n",
        "      reading = int(input(\"Enter Reading Score: \"))\n",
        "      writing = int(input(\"Enter Writing Score: \"))\n",
        "\n",
        "      total = math + reading + writing\n",
        "      recommendation = recommend_course(total)\n",
        "\n",
        "      print(f\"Total Score: {total}\")\n",
        "      print(f\"Course Recommendation: {recommendation}\")\n",
        "    elif choice==17:\n",
        "       bar_plot()\n",
        "    elif choice==18:\n",
        "       scatter_plot()\n",
        "    elif choice==19:\n",
        "        test_effect()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}